---
title: 'Amazon Machine Learning Conference (AMLC 2025)'
date: 2025-11-06
permalink: /posts/2025/11/amlc-2025/
tags:
  - science
---

I've spent the last few days in Seattle at Amazon’s internal Machine Learning Conference (AMLC). If last year was defined by the frontier of GenAI capabilities, this year the focus shifted decisively toward agents, reliability, and real-world deployment. The conversation has moved from _“Can we do X?”_ to _“How do we evaluate, govern, and safely operationalize X at scale?”_. It felt like a distinctly Amazonian event: pragmatic, execution-oriented, and full of hallway discussions about shipping real systems and delivering customer impact.

I participated in the _Machine Learning for Healthcare Roundtable_ and gave a talk on [LLM trustworthiness in medical product question answering](https://daniellopezmartinez.com/talks/2025-11-04-talk-amlc), drawing on my earlier work on [Rufus](https://www.aboutamazon.com/news/retail/amazon-rufus). But the real highlight was learning from the impressive work happening across teams. Below are a few themes that stood out to me.

<img src='/images/blog/2025-11-07-amlc.jpeg' width="700" height="400">


## Pattie Maes on human flourishing with AI

One of my favorite moments at AMLC was seeing [Pattie Maes](https://www.media.mit.edu/people/pattie/overview/) give a keynote. Pattie is a professor at the [MIT Media Lab](https://www.media.mit.edu/), where I did my PhD, and she has been thinking about agents and augmentation for decades, long before today’s wave of foundation models. She pioneered the concept of "[software agents](http://ieeexplore.ieee.org/document/612209)" in the 90s.

Her keynote traced an arc from early work on robotic and software agents to modern research on contextual, multimodal assistants that help with memory, daily functioning and decision making.  But the core of her talk was a clear challenge of AI: the impact of AI on people is not uniformly beneficial. While always-on, agentic AI promises to improve productivity, current evidence suggests the impact is "mixed at best". Pattie emphasized the risk of deskilling, where reliance on AI atrophies human capability over time, and pointed to a growing body of studies showing that pervasive AI assistance can influence or weaken fundamental human capacities. 

For example, she cited a striking [Lancet study](https://www.thelancet.com/journals/langas/article/PIIS2468-1253(25)00133-5/abstract) in which oncologists who used AI assistance for three months improved their diagnostic accuracy during that period. However, when the AI was taken away, they were 20% less effective at identifying cancerous lesions than they had been before the experiment began. In addition to this, she also pointed out AI's tendency towards sycophancy, prioritizing telling users what they want to hear over the truth, which also homogenizes thought and reduces critical thinking. She also noted that in her group's [recent work](https://arxiv.org/pdf/2506.08872v1), students using ChatGPT showed significantly less prefrontal cortex activity (the area associated with thinking) compared to those writing essays with standard tools.

This creates a paradox for us as builders: How do we build systems that assist without automating away the user's agency? To tackle this, Pattie described new initiatives at the MIT Media Lab aimed at building a science of human–AI interaction, such as the [Advancing Humans with AI (AHA)](https://www.media.mit.edu/groups/aha/overview/) program. 

Among other efforts, the AHA team is working on benchmarks for the human impact of AI, analogous to today’s technical benchmarks (e.g. for accuracy, latency, etc.), and an “atlas” mapping how design choices influence understanding, critical thinking, social connection and well-being.

Pattie’s keynote was a powerful reminder that as we push toward more capable and autonomous AI systems, we must stay grounded in the question of how they reshape human skills. AI will not only transform workflows; it will transform the people inside them.
